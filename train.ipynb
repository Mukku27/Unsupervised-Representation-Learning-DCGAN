{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "nhHbo0XFlg1y",
        "outputId": "597797a0-d994-40c6-8a2f-4ad24f7504fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-46e628176de5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitialize_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision as torchvision\n",
        "from torchvision import datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from model import Discriminator,Generator,initialize_weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LEARNING_RATE=2e-4\n",
        "Batch_size=128\n",
        "image_size=64\n",
        "channels_img=1\n",
        "z_dim=100\n",
        "num_epochs=10\n",
        "features_disc=64\n",
        "features_gen=64\n",
        "transforms=transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(channels_img)],[0.5 for _ in range(channels_img)]\n",
        "        ),\n",
        "\n",
        "    ]\n",
        "\n",
        ")\n",
        "dataset=datasets.MNIST(root=\"dataset/\",train=True,transform=transforms,download=True)\n",
        "loader=DataLoader(dataset,batch_size=Batch_size,shuffle=True)\n",
        "gen=Generator(z_dim,channels_img,features_gen).to(device)\n",
        "disc=Discriminator(channels_img,features_disc).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(disc)\n",
        "opt_gen=optim.Adam(gen.parameters(),lr=LEARNING_RATE,betas=(0.5,0.999))\n",
        "opt_disc=optim.Adam(disc.parameters(),lr=LEARNING_RATE,betas=(0.5,0.999))\n",
        "criterion=nn.BCELoss()\n",
        "fixed_noise=torch.randn(32,z_dim,1,1).to(device)\n",
        "writer_real=SummaryWriter(f\"logs/real\")\n",
        "writer_fake=SummaryWriter(f\"logs/fake\")\n",
        "step=0\n",
        "gen.train()\n",
        "disc.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK-kJDuyu0Fu",
        "outputId": "c9796890-0bf4-490f-c63c-e0b10d88e593"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (disc): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (4): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(real,_) in enumerate(loader):\n",
        "    real=real.to(device)\n",
        "    noise=torch.randn(Batch_size,z_dim,1,1).to(device)\n",
        "    fake=gen(noise)\n",
        "\n",
        "    #train_discriminator\n",
        "    noise=torch.randn(Batch_size,z_dim).to(device)\n",
        "\n",
        "    disc_real=disc(real).view(-1)\n",
        "    lossD_real=criterion(disc_real,torch.ones_like(disc_real))\n",
        "    disc_fake=disc(fake).view(-1)\n",
        "    lossD_fake=criterion(disc_fake,torch.zeros_like(disc_fake))\n",
        "    lossD=(lossD_fake+lossD_real)/2\n",
        "    disc.zero_grad()\n",
        "    lossD.backward(retain_graph=True)\n",
        "    opt_disc.step()\n",
        "\n",
        "\n",
        "    #train_generator\n",
        "    output=disc(fake).view(-1)\n",
        "    lossG=criterion(output,torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    lossG.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "\n",
        "    if batch_idx==0:\n",
        "       print(f\"Epochs[{epoch}\\ {num_epochs}]/\"\n",
        "             f\"Loss D:{lossD:.4f},Loss G:{lossG:.4f}\")\n",
        "       with torch.no_grad():\n",
        "         fake=gen(fixed_noise)\n",
        "\n",
        "         img_grid_fake=torchvision.utils.make_grid(fake[:32],normalize=True)\n",
        "         img_grid_real=torchvision.utils.make_grid(real[:32],normalize=True)\n",
        "\n",
        "\n",
        "         writer_fake.add_image(\n",
        "            \"MNIST fake images\",img_grid_fake,global_step=step\n",
        "        )\n",
        "         writer_real.add_image(\n",
        "            \"MNIST real images\",img_grid_real,global_step=step\n",
        "        )\n",
        "         step+=1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "bpL2Mr7I43Ye",
        "outputId": "ee1ce754-ce10-4194-c78e-a2b1ea3fe786"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs[0\\ 10]/Loss D:6.8022,Loss G:5.4784\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1872732195bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlossG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlossG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}